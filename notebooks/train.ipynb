{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: findspark in /home/ubuntu/.local/lib/python3.8/site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/12/07 18:11:42 WARN S3ABlockOutputStream: Application invoked the Syncable API against stream writing to dataproc/hadoop/var/log/spark/apps/local-1733595100267.inprogress. This is unsupported\n"
     ]
    }
   ],
   "source": [
    "os.environ['PYSPARK_PYTHON'] = './venv/bin/python'\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master('local[*]')\\\n",
    "    .appName('Spark ML Research')\\\n",
    "    .config('spark.sql.repl.eagerEval.enabled', True) \\\n",
    "    .config('spark.yarn.dist.archives', 's3a://pyspark-venvs/mlflow-dataproc-2.1.18.tar.gz#venv')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считываем данные "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Survived</th><th>Pclass</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Fare</th><th>Embarked</th></tr>\n",
       "<tr><td>0</td><td>3</td><td>male</td><td>22.0</td><td>1</td><td>0</td><td>7.25</td><td>S</td></tr>\n",
       "<tr><td>1</td><td>1</td><td>female</td><td>38.0</td><td>1</td><td>0</td><td>71.2833</td><td>C</td></tr>\n",
       "<tr><td>1</td><td>3</td><td>female</td><td>26.0</td><td>0</td><td>0</td><td>7.925</td><td>S</td></tr>\n",
       "<tr><td>1</td><td>1</td><td>female</td><td>35.0</td><td>1</td><td>0</td><td>53.1</td><td>S</td></tr>\n",
       "<tr><td>0</td><td>3</td><td>male</td><td>35.0</td><td>0</td><td>0</td><td>8.05</td><td>S</td></tr>\n",
       "<tr><td>0</td><td>1</td><td>male</td><td>54.0</td><td>0</td><td>0</td><td>51.8625</td><td>S</td></tr>\n",
       "<tr><td>0</td><td>3</td><td>male</td><td>2.0</td><td>3</td><td>1</td><td>21.075</td><td>S</td></tr>\n",
       "<tr><td>1</td><td>3</td><td>female</td><td>27.0</td><td>0</td><td>2</td><td>11.1333</td><td>S</td></tr>\n",
       "<tr><td>1</td><td>2</td><td>female</td><td>14.0</td><td>1</td><td>0</td><td>30.0708</td><td>C</td></tr>\n",
       "<tr><td>1</td><td>3</td><td>female</td><td>4.0</td><td>1</td><td>1</td><td>16.7</td><td>S</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+------+------+----+-----+-----+-------+--------+\n",
       "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|\n",
       "+--------+------+------+----+-----+-----+-------+--------+\n",
       "|       0|     3|  male|22.0|    1|    0|   7.25|       S|\n",
       "|       1|     1|female|38.0|    1|    0|71.2833|       C|\n",
       "|       1|     3|female|26.0|    0|    0|  7.925|       S|\n",
       "|       1|     1|female|35.0|    1|    0|   53.1|       S|\n",
       "|       0|     3|  male|35.0|    0|    0|   8.05|       S|\n",
       "|       0|     1|  male|54.0|    0|    0|51.8625|       S|\n",
       "|       0|     3|  male| 2.0|    3|    1| 21.075|       S|\n",
       "|       1|     3|female|27.0|    0|    2|11.1333|       S|\n",
       "|       1|     2|female|14.0|    1|    0|30.0708|       C|\n",
       "|       1|     3|female| 4.0|    1|    1|   16.7|       S|\n",
       "+--------+------+------+----+-----+-----+-------+--------+"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv(\n",
    "    's3a://mlops204-dataproc-bucket/data/titanic/train.csv', \n",
    "    header=True, \n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "df = df.select([\n",
    "    'Survived',\n",
    "    'Pclass',\n",
    "    'Sex',\n",
    "    'Age',\n",
    "    'SibSp',\n",
    "    'Parch',\n",
    "    'Fare',\n",
    "    'Embarked'\n",
    "]).na.drop()\n",
    "\n",
    "df.limit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Строим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, OneHotEncoder, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_index = StringIndexer(inputCol='Sex', outputCol='SexIndex')\n",
    "gender_encoder = OneHotEncoder(inputCol='SexIndex', outputCol='SexVector')\n",
    "\n",
    "embark_indexer = StringIndexer(inputCol='Embarked', outputCol='EmbarkedIndex')\n",
    "embark_encoder = OneHotEncoder(inputCol='EmbarkedIndex', outputCol='EmbarkVector')\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        'Pclass',\n",
    "        'SexVector',\n",
    "        'Age',\n",
    "        'SibSp',\n",
    "        'Parch',\n",
    "        'Fare',\n",
    "        'EmbarkVector'\n",
    "    ],\n",
    "    outputCol='features'\n",
    ")\n",
    "\n",
    "dataproc = Pipeline(stages=[\n",
    "    gender_index,\n",
    "    embark_indexer,\n",
    "    gender_encoder,\n",
    "    embark_encoder,\n",
    "    assembler\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Survived</th><th>Pclass</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Fare</th><th>Embarked</th><th>SexIndex</th><th>EmbarkedIndex</th><th>SexVector</th><th>EmbarkVector</th><th>features</th></tr>\n",
       "<tr><td>0</td><td>3</td><td>male</td><td>22.0</td><td>1</td><td>0</td><td>7.25</td><td>S</td><td>0.0</td><td>0.0</td><td>(1,[0],[1.0])</td><td>(2,[0],[1.0])</td><td>[3.0,1.0,22.0,1.0...</td></tr>\n",
       "<tr><td>1</td><td>1</td><td>female</td><td>38.0</td><td>1</td><td>0</td><td>71.2833</td><td>C</td><td>1.0</td><td>1.0</td><td>(1,[],[])</td><td>(2,[1],[1.0])</td><td>[1.0,0.0,38.0,1.0...</td></tr>\n",
       "<tr><td>1</td><td>3</td><td>female</td><td>26.0</td><td>0</td><td>0</td><td>7.925</td><td>S</td><td>1.0</td><td>0.0</td><td>(1,[],[])</td><td>(2,[0],[1.0])</td><td>(8,[0,2,5,6],[3.0...</td></tr>\n",
       "<tr><td>1</td><td>1</td><td>female</td><td>35.0</td><td>1</td><td>0</td><td>53.1</td><td>S</td><td>1.0</td><td>0.0</td><td>(1,[],[])</td><td>(2,[0],[1.0])</td><td>[1.0,0.0,35.0,1.0...</td></tr>\n",
       "<tr><td>0</td><td>3</td><td>male</td><td>35.0</td><td>0</td><td>0</td><td>8.05</td><td>S</td><td>0.0</td><td>0.0</td><td>(1,[0],[1.0])</td><td>(2,[0],[1.0])</td><td>[3.0,1.0,35.0,0.0...</td></tr>\n",
       "<tr><td>0</td><td>1</td><td>male</td><td>54.0</td><td>0</td><td>0</td><td>51.8625</td><td>S</td><td>0.0</td><td>0.0</td><td>(1,[0],[1.0])</td><td>(2,[0],[1.0])</td><td>[1.0,1.0,54.0,0.0...</td></tr>\n",
       "<tr><td>0</td><td>3</td><td>male</td><td>2.0</td><td>3</td><td>1</td><td>21.075</td><td>S</td><td>0.0</td><td>0.0</td><td>(1,[0],[1.0])</td><td>(2,[0],[1.0])</td><td>[3.0,1.0,2.0,3.0,...</td></tr>\n",
       "<tr><td>1</td><td>3</td><td>female</td><td>27.0</td><td>0</td><td>2</td><td>11.1333</td><td>S</td><td>1.0</td><td>0.0</td><td>(1,[],[])</td><td>(2,[0],[1.0])</td><td>[3.0,0.0,27.0,0.0...</td></tr>\n",
       "<tr><td>1</td><td>2</td><td>female</td><td>14.0</td><td>1</td><td>0</td><td>30.0708</td><td>C</td><td>1.0</td><td>1.0</td><td>(1,[],[])</td><td>(2,[1],[1.0])</td><td>[2.0,0.0,14.0,1.0...</td></tr>\n",
       "<tr><td>1</td><td>3</td><td>female</td><td>4.0</td><td>1</td><td>1</td><td>16.7</td><td>S</td><td>1.0</td><td>0.0</td><td>(1,[],[])</td><td>(2,[0],[1.0])</td><td>[3.0,0.0,4.0,1.0,...</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+------+------+----+-----+-----+-------+--------+--------+-------------+-------------+-------------+--------------------+\n",
       "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|SexIndex|EmbarkedIndex|    SexVector| EmbarkVector|            features|\n",
       "+--------+------+------+----+-----+-----+-------+--------+--------+-------------+-------------+-------------+--------------------+\n",
       "|       0|     3|  male|22.0|    1|    0|   7.25|       S|     0.0|          0.0|(1,[0],[1.0])|(2,[0],[1.0])|[3.0,1.0,22.0,1.0...|\n",
       "|       1|     1|female|38.0|    1|    0|71.2833|       C|     1.0|          1.0|    (1,[],[])|(2,[1],[1.0])|[1.0,0.0,38.0,1.0...|\n",
       "|       1|     3|female|26.0|    0|    0|  7.925|       S|     1.0|          0.0|    (1,[],[])|(2,[0],[1.0])|(8,[0,2,5,6],[3.0...|\n",
       "|       1|     1|female|35.0|    1|    0|   53.1|       S|     1.0|          0.0|    (1,[],[])|(2,[0],[1.0])|[1.0,0.0,35.0,1.0...|\n",
       "|       0|     3|  male|35.0|    0|    0|   8.05|       S|     0.0|          0.0|(1,[0],[1.0])|(2,[0],[1.0])|[3.0,1.0,35.0,0.0...|\n",
       "|       0|     1|  male|54.0|    0|    0|51.8625|       S|     0.0|          0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,54.0,0.0...|\n",
       "|       0|     3|  male| 2.0|    3|    1| 21.075|       S|     0.0|          0.0|(1,[0],[1.0])|(2,[0],[1.0])|[3.0,1.0,2.0,3.0,...|\n",
       "|       1|     3|female|27.0|    0|    2|11.1333|       S|     1.0|          0.0|    (1,[],[])|(2,[0],[1.0])|[3.0,0.0,27.0,0.0...|\n",
       "|       1|     2|female|14.0|    1|    0|30.0708|       C|     1.0|          1.0|    (1,[],[])|(2,[1],[1.0])|[2.0,0.0,14.0,1.0...|\n",
       "|       1|     3|female| 4.0|    1|    1|   16.7|       S|     1.0|          0.0|    (1,[],[])|(2,[0],[1.0])|[3.0,0.0,4.0,1.0,...|\n",
       "+--------+------+------+----+-----+-----+-------+--------+--------+-------------+-------------+-------------+--------------------+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = dataproc.fit(df).transform(df)\n",
    "train_data.limit(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
