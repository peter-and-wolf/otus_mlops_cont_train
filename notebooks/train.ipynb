{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: findspark in /home/ubuntu/.local/lib/python3.8/site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пререквизиты\n",
    "\n",
    "Код в этом ноутбуке будет работать с MLFlow Tracking Server, который запущен на удаленной виртуальной машине. Кроме того, артефакты моделирования сохранятся в S3-бакет в YC. Поэтому **прежде чем выполнять ячейки с кодом**, убедитесь, что установлены следующие переменные окружения:\n",
    "\n",
    "```bash\n",
    "MLFLOW_S3_ENDPOINT_URL=https://storage.yandexcloud.net/\n",
    "MLFLOW_TRACKING_URI=http://<ip вашей виртуалки с MLFlow>:8000\n",
    "AWS_ACCESS_KEY_ID=<id вашего ключа>\n",
    "AWS_SECRET_ACCESS_KEY=<ваш секретный ключ>\n",
    "```\n",
    "\n",
    "Установить переменные я рекомендую так:\n",
    "\n",
    "1. Создаете файл (в той же директории, откуда запускаете `jupyter`) `.env`.\n",
    "2. Записываете в файл `env` следующее содержание:\n",
    "   \n",
    "```bash\n",
    "MLFLOW_S3_ENDPOINT_URL=https://storage.yandexcloud.net/\n",
    "MLFLOW_TRACKING_URI=http://<ip вашей виртуалки с MLFlow>:8000\n",
    "AWS_ACCESS_KEY_ID=<id вашего ключа>\n",
    "AWS_SECRET_ACCESS_KEY=<ваш секретный ключ>\n",
    "```\n",
    "3. Устанавливаете пакет `python-dotenv`\n",
    "\n",
    "```bash\n",
    "pip install python-dotenv`\n",
    "```\n",
    "\n",
    "4. Выполняете следующую ячейку с кодом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализируем spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/12/11 15:39:20 WARN S3ABlockOutputStream: Application invoked the Syncable API against stream writing to dataproc/hadoop/var/log/spark/apps/local-1733931557916.inprogress. This is unsupported\n"
     ]
    }
   ],
   "source": [
    "os.environ['PYSPARK_PYTHON'] = './venv/bin/python'\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master('local[*]')\\\n",
    "    .appName('Spark ML Research')\\\n",
    "    .config('spark.sql.repl.eagerEval.enabled', True) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", os.environ['AWS_ACCESS_KEY_ID']) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", os.environ['AWS_SECRET_ACCESS_KEY']) \\\n",
    "    .config('spark.hadoop.fs.s3.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem') \\\n",
    "    .config('spark.yarn.dist.archives', 's3a://pyspark-venvs/mlflow-hyperopt-dataproc-2.1.18.tar.gz#venv')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считываем данные "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Survived</th><th>Pclass</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Fare</th><th>Embarked</th></tr>\n",
       "<tr><td>0</td><td>3</td><td>male</td><td>22.0</td><td>1</td><td>0</td><td>7.25</td><td>S</td></tr>\n",
       "<tr><td>1</td><td>1</td><td>female</td><td>38.0</td><td>1</td><td>0</td><td>71.2833</td><td>C</td></tr>\n",
       "<tr><td>1</td><td>3</td><td>female</td><td>26.0</td><td>0</td><td>0</td><td>7.925</td><td>S</td></tr>\n",
       "<tr><td>1</td><td>1</td><td>female</td><td>35.0</td><td>1</td><td>0</td><td>53.1</td><td>S</td></tr>\n",
       "<tr><td>0</td><td>3</td><td>male</td><td>35.0</td><td>0</td><td>0</td><td>8.05</td><td>S</td></tr>\n",
       "<tr><td>0</td><td>1</td><td>male</td><td>54.0</td><td>0</td><td>0</td><td>51.8625</td><td>S</td></tr>\n",
       "<tr><td>0</td><td>3</td><td>male</td><td>2.0</td><td>3</td><td>1</td><td>21.075</td><td>S</td></tr>\n",
       "<tr><td>1</td><td>3</td><td>female</td><td>27.0</td><td>0</td><td>2</td><td>11.1333</td><td>S</td></tr>\n",
       "<tr><td>1</td><td>2</td><td>female</td><td>14.0</td><td>1</td><td>0</td><td>30.0708</td><td>C</td></tr>\n",
       "<tr><td>1</td><td>3</td><td>female</td><td>4.0</td><td>1</td><td>1</td><td>16.7</td><td>S</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+------+------+----+-----+-----+-------+--------+\n",
       "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|\n",
       "+--------+------+------+----+-----+-----+-------+--------+\n",
       "|       0|     3|  male|22.0|    1|    0|   7.25|       S|\n",
       "|       1|     1|female|38.0|    1|    0|71.2833|       C|\n",
       "|       1|     3|female|26.0|    0|    0|  7.925|       S|\n",
       "|       1|     1|female|35.0|    1|    0|   53.1|       S|\n",
       "|       0|     3|  male|35.0|    0|    0|   8.05|       S|\n",
       "|       0|     1|  male|54.0|    0|    0|51.8625|       S|\n",
       "|       0|     3|  male| 2.0|    3|    1| 21.075|       S|\n",
       "|       1|     3|female|27.0|    0|    2|11.1333|       S|\n",
       "|       1|     2|female|14.0|    1|    0|30.0708|       C|\n",
       "|       1|     3|female| 4.0|    1|    1|   16.7|       S|\n",
       "+--------+------+------+----+-----+-----+-------+--------+"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv(\n",
    "    's3a://mlops204-dataproc-bucket/data/titanic/train.csv', \n",
    "    header=True, \n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "df = df.select([\n",
    "    'Survived',\n",
    "    'Pclass',\n",
    "    'Sex',\n",
    "    'Age',\n",
    "    'SibSp',\n",
    "    'Parch',\n",
    "    'Fare',\n",
    "    'Embarked'\n",
    "]).na.drop()\n",
    "\n",
    "df.limit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Конструируем пайплайн обработки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, OneHotEncoder, StringIndexer\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_index = StringIndexer(inputCol='Sex', outputCol='SexIndex')\n",
    "gender_encoder = OneHotEncoder(inputCol='SexIndex', outputCol='SexVector')\n",
    "\n",
    "embark_indexer = StringIndexer(inputCol='Embarked', outputCol='EmbarkedIndex')\n",
    "embark_encoder = OneHotEncoder(inputCol='EmbarkedIndex', outputCol='EmbarkVector')\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        'Pclass',\n",
    "        'SexVector',\n",
    "        'Age',\n",
    "        'SibSp',\n",
    "        'Parch',\n",
    "        'Fare',\n",
    "        'EmbarkVector'\n",
    "    ],\n",
    "    outputCol='Features'\n",
    ")\n",
    "\n",
    "dataproc = Pipeline(stages=[\n",
    "    gender_index,\n",
    "    embark_indexer,\n",
    "    gender_encoder,\n",
    "    embark_encoder,\n",
    "    assembler\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Survived</th><th>Pclass</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Fare</th><th>Embarked</th><th>SexIndex</th><th>EmbarkedIndex</th><th>SexVector</th><th>EmbarkVector</th><th>Features</th></tr>\n",
       "<tr><td>0</td><td>3</td><td>male</td><td>22.0</td><td>1</td><td>0</td><td>7.25</td><td>S</td><td>0.0</td><td>0.0</td><td>(1,[0],[1.0])</td><td>(2,[0],[1.0])</td><td>[3.0,1.0,22.0,1.0...</td></tr>\n",
       "<tr><td>1</td><td>1</td><td>female</td><td>38.0</td><td>1</td><td>0</td><td>71.2833</td><td>C</td><td>1.0</td><td>1.0</td><td>(1,[],[])</td><td>(2,[1],[1.0])</td><td>[1.0,0.0,38.0,1.0...</td></tr>\n",
       "<tr><td>1</td><td>3</td><td>female</td><td>26.0</td><td>0</td><td>0</td><td>7.925</td><td>S</td><td>1.0</td><td>0.0</td><td>(1,[],[])</td><td>(2,[0],[1.0])</td><td>(8,[0,2,5,6],[3.0...</td></tr>\n",
       "<tr><td>1</td><td>1</td><td>female</td><td>35.0</td><td>1</td><td>0</td><td>53.1</td><td>S</td><td>1.0</td><td>0.0</td><td>(1,[],[])</td><td>(2,[0],[1.0])</td><td>[1.0,0.0,35.0,1.0...</td></tr>\n",
       "<tr><td>0</td><td>3</td><td>male</td><td>35.0</td><td>0</td><td>0</td><td>8.05</td><td>S</td><td>0.0</td><td>0.0</td><td>(1,[0],[1.0])</td><td>(2,[0],[1.0])</td><td>[3.0,1.0,35.0,0.0...</td></tr>\n",
       "<tr><td>0</td><td>1</td><td>male</td><td>54.0</td><td>0</td><td>0</td><td>51.8625</td><td>S</td><td>0.0</td><td>0.0</td><td>(1,[0],[1.0])</td><td>(2,[0],[1.0])</td><td>[1.0,1.0,54.0,0.0...</td></tr>\n",
       "<tr><td>0</td><td>3</td><td>male</td><td>2.0</td><td>3</td><td>1</td><td>21.075</td><td>S</td><td>0.0</td><td>0.0</td><td>(1,[0],[1.0])</td><td>(2,[0],[1.0])</td><td>[3.0,1.0,2.0,3.0,...</td></tr>\n",
       "<tr><td>1</td><td>3</td><td>female</td><td>27.0</td><td>0</td><td>2</td><td>11.1333</td><td>S</td><td>1.0</td><td>0.0</td><td>(1,[],[])</td><td>(2,[0],[1.0])</td><td>[3.0,0.0,27.0,0.0...</td></tr>\n",
       "<tr><td>1</td><td>2</td><td>female</td><td>14.0</td><td>1</td><td>0</td><td>30.0708</td><td>C</td><td>1.0</td><td>1.0</td><td>(1,[],[])</td><td>(2,[1],[1.0])</td><td>[2.0,0.0,14.0,1.0...</td></tr>\n",
       "<tr><td>1</td><td>3</td><td>female</td><td>4.0</td><td>1</td><td>1</td><td>16.7</td><td>S</td><td>1.0</td><td>0.0</td><td>(1,[],[])</td><td>(2,[0],[1.0])</td><td>[3.0,0.0,4.0,1.0,...</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+------+------+----+-----+-----+-------+--------+--------+-------------+-------------+-------------+--------------------+\n",
       "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|SexIndex|EmbarkedIndex|    SexVector| EmbarkVector|            Features|\n",
       "+--------+------+------+----+-----+-----+-------+--------+--------+-------------+-------------+-------------+--------------------+\n",
       "|       0|     3|  male|22.0|    1|    0|   7.25|       S|     0.0|          0.0|(1,[0],[1.0])|(2,[0],[1.0])|[3.0,1.0,22.0,1.0...|\n",
       "|       1|     1|female|38.0|    1|    0|71.2833|       C|     1.0|          1.0|    (1,[],[])|(2,[1],[1.0])|[1.0,0.0,38.0,1.0...|\n",
       "|       1|     3|female|26.0|    0|    0|  7.925|       S|     1.0|          0.0|    (1,[],[])|(2,[0],[1.0])|(8,[0,2,5,6],[3.0...|\n",
       "|       1|     1|female|35.0|    1|    0|   53.1|       S|     1.0|          0.0|    (1,[],[])|(2,[0],[1.0])|[1.0,0.0,35.0,1.0...|\n",
       "|       0|     3|  male|35.0|    0|    0|   8.05|       S|     0.0|          0.0|(1,[0],[1.0])|(2,[0],[1.0])|[3.0,1.0,35.0,0.0...|\n",
       "|       0|     1|  male|54.0|    0|    0|51.8625|       S|     0.0|          0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,54.0,0.0...|\n",
       "|       0|     3|  male| 2.0|    3|    1| 21.075|       S|     0.0|          0.0|(1,[0],[1.0])|(2,[0],[1.0])|[3.0,1.0,2.0,3.0,...|\n",
       "|       1|     3|female|27.0|    0|    2|11.1333|       S|     1.0|          0.0|    (1,[],[])|(2,[0],[1.0])|[3.0,0.0,27.0,0.0...|\n",
       "|       1|     2|female|14.0|    1|    0|30.0708|       C|     1.0|          1.0|    (1,[],[])|(2,[1],[1.0])|[2.0,0.0,14.0,1.0...|\n",
       "|       1|     3|female| 4.0|    1|    1|   16.7|       S|     1.0|          0.0|    (1,[],[])|(2,[0],[1.0])|[3.0,0.0,4.0,1.0,...|\n",
       "+--------+------+------+----+-----+-----+-------+--------+--------+-------------+-------------+-------------+--------------------+"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ready_data = dataproc.fit(df).transform(df)\n",
    "ready_data.limit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбираем гиперпараметры и тренируем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import mlflow\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, SparkTrials, Trials\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(\"mlflow\")\n",
    "# Set log level to debugging\n",
    "logger.setLevel(logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем пространство поиска для hyperopt\n",
    "search_space = {\n",
    "    'regParam': hp.lognormal('regParam', 0, 1.0),\n",
    "    'fitIntercept': hp.choice('fitIntercept', [False, True])\n",
    "}\n",
    "\n",
    "def objective(params, train_data, test_data):\n",
    "    print(params)\n",
    "\n",
    "    lr = LogisticRegression()\\\n",
    "        .setMaxIter(1000)\\\n",
    "        .setRegParam(params['regParam'])\\\n",
    "        .setFeaturesCol('Features')\\\n",
    "        .setLabelCol('Survived')\n",
    "\n",
    "    evaluator = BinaryClassificationEvaluator()\\\n",
    "            .setLabelCol('Survived')\n",
    "\n",
    "    lg_model = lr.fit(train_data)\n",
    "\n",
    "    auc = evaluator.evaluate(lg_model.transform(test_data))\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric('auc', auc)\n",
    "    \n",
    "    return {'loss': -auc, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fitIntercept': True, 'regParam': 1.255119385583293}                                                                                                                                                                                         \n",
      "  0%|                                                                                                                                                                                                  | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/12/11 15:39:42 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/12/11 15:39:42 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "{'fitIntercept': True, 'regParam': 0.48254977467864435}                                                                                                                                                                                       \n",
      "{'fitIntercept': False, 'regParam': 0.685966186664396}                                                                                                                                                                                        \n",
      "{'fitIntercept': True, 'regParam': 0.19815190356438855}                                                                                                                                                                                       \n",
      "{'fitIntercept': True, 'regParam': 0.6978407092937315}                                                                                                                                                                                        \n",
      "{'fitIntercept': False, 'regParam': 1.172029705258217}                                                                                                                                                                                        \n",
      "{'fitIntercept': True, 'regParam': 2.4695747810516844}                                                                                                                                                                                        \n",
      "{'fitIntercept': True, 'regParam': 0.6382916685670463}                                                                                                                                                                                        \n",
      "{'fitIntercept': False, 'regParam': 3.1139179453890184}                                                                                                                                                                                       \n",
      "{'fitIntercept': False, 'regParam': 5.042059102259505}                                                                                                                                                                                        \n",
      "\n",
      "00%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:22<00:00,  2.22s/trial, best loss: -0.8592411924119232]"
     ]
    }
   ],
   "source": [
    "train_data, test_data = ready_data.randomSplit([.7, .3])\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "mlflow.set_experiment('classification')\n",
    "\n",
    "best = fmin(\n",
    "    fn=partial(\n",
    "        objective, \n",
    "        train_data=train_data,\n",
    "        test_data=test_data\n",
    "    ),\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=10,\n",
    "    trials=trials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
